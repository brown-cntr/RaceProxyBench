In many high-stakes regulatory and public service contexts, the accurate estimation of race is essential to identify and address algorithmic biases. Because race data is often unavailable or 
legally restricted, institutions like the IRS, Consumer Financial Protection Bureau, and the Department of Justice rely on methods such as Bayesian Improved Surname Geocoding (BISG) to estimate 
race using only proxies like last names and zip codes. Despite its widespread usage, BISG is a method with known vulnerabilities, particularly its sensitivity to input noise and other contextual 
factors, and it may be limited in settings where proxy information is incomplete or inconsistent. 

This project seeks to evaluate the contexts in which BISG can be trusted, explore alternative proxy estimation methods, and test the robustness of various proxy estimation methods under varying
conditions for surname and geocode. In doing so, the project aims to enhance the reliability of bias detection in algorithmic decision-making and ensure more transparent, equitable outcomes in public
and regulatory settings.
